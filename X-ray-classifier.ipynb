{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CODE TAKEN DIRECTLY FROM\n",
        "#https://github.com/vicely07/Pneumonet-A-Pytorch-Chest-Xray-Pneumonia-Detection/blob/main/Pytorch_Xray_Pneumonia_Detection_project.ipynb\n",
        "#ALL CREDITS GO DIRECTLY TO THIS UPLOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cVv3dQxBER5W"
      },
      "outputs": [],
      "source": [
        "###import packages for project\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "import PIL\n",
        "import scipy.ndimage as nd\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "apqvFsyyivXE"
      },
      "source": [
        "The more data, the better the model will learn. Hence, apply some data augmentation to generate different variations of the original data to increase the sample size for training, validation and testing process. This augmentation can be performed by defining a set of transforming functions in the torchvision module. The detailed codes are as following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2_1_quCRER5c"
      },
      "outputs": [],
      "source": [
        "## data augmentation with torchvision.transforms\n",
        "\n",
        "transformers = {'train_transforms' : transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "]),\n",
        "'test_transforms' : transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "]),\n",
        "'valid_transforms' : transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-YmxazG7ER5g"
      },
      "outputs": [],
      "source": [
        "trans = ['train_transforms','valid_transforms','test_transforms']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg0d2aUGi6QB"
      },
      "source": [
        "After defining the transformers, now we can use torchvision.datasets.ImageFolder module we load images from our dataset directory and apply the predefined transformers on them as following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S49zsvRIER5k"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(sys.path[0], \"image_data_w_generative_data/\")\n",
        "#path = \"/content/drive/My Drive/FB-Ai-Hackathon/pneumonia-pytorch-localization/Data/\"\n",
        "categories = ['train','val','test']\n",
        "dset = {x : torchvision.datasets.ImageFolder(path+x, transform=transformers[y]) for x,y in zip(categories, trans)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x8YFYJocjDLY"
      },
      "source": [
        "After refreshing your memory on the basics, we can start with this project using the COVID chest X-ray data. First, we need to initialize our model class by calling the nn.Module, which create a graph-like structure of our network. In particularly, as we mentioned earlier, the pretrained model of Resnet152 was used in our training process. This transfer learning give us a big advantage in retraining on Hence, we need to define our ResNet-152 in the init of nn.Module for transfer learning. Then after define the init function, we need to create a forward function as part of the requirement for Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xUuuu0kdER5w"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = {x : len(dset[x]) for x in categories}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "6AKqzPHHER5n",
        "outputId": "64b2f86b-3950-41c8-ea17-87ecd37006aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 5973\n",
            "val: 16\n",
            "test: 624\n"
          ]
        }
      ],
      "source": [
        "for x in categories:\n",
        "  print('{}: {}'.format(x,dataset_sizes[x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BH2joa0PER5r"
      },
      "outputs": [],
      "source": [
        "num_threads = 0\n",
        "dataloaders =  {x : torch.utils.data.DataLoader(dset[x], batch_size=16, shuffle=True, num_workers=num_threads)\n",
        "               for x in categories} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TZQP5Zk2zkzj"
      },
      "source": [
        "After refreshing your memory on the basics, we can start with this project using the COVID-19 & Pneumonia chest X-ray data. First, we need to initialize our model class by calling the nn.Module, which create a graph-like structure of our network. In particularly, as we mentioned earlier, the pretrained model of Resnet152 was used in our training process. This transfer learning give us a big advantage in retraining on Hence, we need to define our ResNet-152 in the init of nn.Module for transfer learning. Then after define the init function, we need to create a forward function as part of the requirement for Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g410XI1iER51"
      },
      "outputs": [],
      "source": [
        "##Build model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = torchvision.models.resnet152(pretrained=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.model.fc.in_features,2),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "        for params in self.model.parameters():\n",
        "            params.requires_grad = False\n",
        "        self.model.fc = self.classifier\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def fit(self, dataloaders, num_epochs):\n",
        "        loss_arr = []\n",
        "        epoch_acc_arr = []\n",
        "        train_on_gpu = torch.cuda.is_available()\n",
        "        optimizer = optim.Adam(self.model.fc.parameters())\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, 4)\n",
        "        criterion = nn.NLLLoss()\n",
        "        since = time.time()\n",
        "        \n",
        "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "        best_acc =0.0\n",
        "        if train_on_gpu:\n",
        "            self.model = self.model.cuda()\n",
        "        for epoch in range(1, num_epochs+1):\n",
        "            print(\"epoch {}/{}\".format(epoch, num_epochs))\n",
        "            print(\"-\" * 10)\n",
        "            \n",
        "            for phase in ['train','test']:\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "                    self.model.train()\n",
        "                else:\n",
        "                    self.model.eval()\n",
        "                \n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0.0\n",
        "                \n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    if train_on_gpu:\n",
        "                        inputs = inputs.cuda()\n",
        "                        labels = labels.cuda()\n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = self.model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        \n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "                print(\"{} loss:  {:.4f}  acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
        "                loss_arr.append(epoch_loss)\n",
        "                epoch_acc_arr.append(epoch_acc)\n",
        "                \n",
        "                if phase == 'test' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "                # print(loss_arr)\n",
        "                # print(epoch_acc_arr)\n",
        "            \n",
        "\n",
        "        \n",
        "        time_elapsed = time.time() - since\n",
        "        print('time completed: {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 600))\n",
        "        print(\"best val acc: {:.4f}\".format(best_acc))\n",
        "        \n",
        "        self.model.load_state_dict(best_model_wts)\n",
        "        return self.model, loss_arr, epoch_acc_arr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdwvzSVzxlF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "5baf385be8734545b0147c7be560a93b",
            "a68ef2d7615e4a2ea59b60096641feda",
            "3dda626232ea4e3eb54d4373b97e57e3",
            "3ca6c128612247ada560a885c64a3f4b",
            "9a040faf346a49f9917f85a89f5c275c",
            "db01eaf8d2194977a50b4da6ce333ae7",
            "cb638aee7419466f8f4be88131bdafe1",
            "6ca6783e279b4ed284614216481e9531"
          ]
        },
        "id": "B9hubqe3ER54",
        "outputId": "76253303-7af5-43d2-cd9e-792273a400b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kimis\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kimis\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kimis\\miniconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss:  0.3225  acc: 0.8557\n",
            "test loss:  0.4614  acc: 0.7740\n",
            "epoch 2/10\n",
            "----------\n",
            "train loss:  0.2746  acc: 0.8867\n",
            "test loss:  0.4851  acc: 0.7532\n",
            "epoch 3/10\n",
            "----------\n",
            "train loss:  0.2461  acc: 0.8969\n",
            "test loss:  0.4394  acc: 0.7901\n",
            "epoch 4/10\n",
            "----------\n",
            "train loss:  0.2146  acc: 0.9096\n",
            "test loss:  0.4567  acc: 0.7821\n",
            "epoch 5/10\n",
            "----------\n",
            "train loss:  0.1993  acc: 0.9181\n",
            "test loss:  0.5166  acc: 0.7804\n",
            "epoch 6/10\n",
            "----------\n",
            "train loss:  0.2063  acc: 0.9144\n",
            "test loss:  0.4839  acc: 0.7901\n",
            "epoch 7/10\n",
            "----------\n",
            "train loss:  0.2131  acc: 0.9094\n",
            "test loss:  0.4673  acc: 0.7853\n",
            "epoch 8/10\n",
            "----------\n",
            "train loss:  0.2034  acc: 0.9173\n",
            "test loss:  0.5129  acc: 0.7869\n",
            "epoch 9/10\n",
            "----------\n",
            "train loss:  0.2040  acc: 0.9188\n",
            "test loss:  0.4946  acc: 0.7853\n",
            "epoch 10/10\n",
            "----------\n",
            "train loss:  0.2000  acc: 0.9203\n",
            "test loss:  0.5358  acc: 0.7708\n",
            "time completed: 10m 11s\n",
            "best val acc: 0.7901\n"
          ]
        }
      ],
      "source": [
        "# Calling the model and fit on training data:\n",
        "model = Model()\n",
        "model_ft, loss_arr, epoch_acc_arr = model.fit(dataloaders,10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mAt0LcpueSTB"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'classifier_model_dicts/classifier_model_20_percent_generative')\n",
        "\n",
        "np.save(\"training_losses_time_series/Classifier_20_percent_generative_loss_arr\", loss_arr, allow_pickle= True)\n",
        "empt = []\n",
        "for element in epoch_acc_arr:\n",
        "    empt.append(float(element))\n",
        "np.save(\"training_losses_time_series/Classifier_20_percent_generative_acc_arr\", empt, allow_pickle= True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x6CySabz0B8W"
      },
      "source": [
        "When we want to load this trained weights back to the model for prediction on new data, we just need to follow these lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "S2lpQb9RzTDL"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model for prediction\n",
        "state_dict = torch.load(\"classifier_model_dicts/classifier_model_20_percent_generative\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model_ft = model.model\n",
        "model_ft = model_ft.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A692vtI5ER6E"
      },
      "outputs": [],
      "source": [
        "loader = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n",
        "                            transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
        "def image_loader(image_name):\n",
        "    image = PIL.Image.open(image_name).convert(\"RGB\")\n",
        "    image = loader(image).float()\n",
        "    image = image.unsqueeze(0)\n",
        "    return image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x1GIQT3g0tT8"
      },
      "source": [
        "After training on the data, we can now test the performance of our model using the accuracy metrics. Let's see what is the accuracy of our model on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "FqFbrSbEoLoK",
        "outputId": "d7388f51-c640-4399-bb32-46e290b9c7a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}') \n",
        "    #model.train()\n",
        "\n",
        "#check_accuracy(dataloaders['train'], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 500 / 624 with accuracy 80.13\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load(\"classifier_model_dicts/classifier_model_base\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model_ft = model.model\n",
        "model_ft = model_ft.eval()\n",
        "\n",
        "check_accuracy(dataloaders['test'], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 507 / 624 with accuracy 81.25\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load(\"classifier_model_dicts/classifier_model_10_percent_generative\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model_ft = model.model\n",
        "model_ft = model_ft.eval()\n",
        "\n",
        "check_accuracy(dataloaders['test'], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5H2lRse7v_gX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 493 / 624 with accuracy 79.01\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load(\"classifier_model_dicts/classifier_model_20_percent_generative\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model_ft = model.model\n",
        "model_ft = model_ft.eval()\n",
        "\n",
        "check_accuracy(dataloaders['test'], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 410 / 624 with accuracy 65.71\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load(\"classifier_model_dicts/classifier_model_all_generative\")\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model_ft = model.model\n",
        "model_ft = model_ft.eval()\n",
        "\n",
        "check_accuracy(dataloaders['test'], model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Raw Cell Format",
    "colab": {
      "collapsed_sections": [],
      "name": "Pytorch-Xray-Pneumonia-Detection-project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ca6c128612247ada560a885c64a3f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca6783e279b4ed284614216481e9531",
            "placeholder": "​",
            "style": "IPY_MODEL_cb638aee7419466f8f4be88131bdafe1",
            "value": " 230M/230M [00:14&lt;00:00, 16.5MB/s]"
          }
        },
        "3dda626232ea4e3eb54d4373b97e57e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db01eaf8d2194977a50b4da6ce333ae7",
            "max": 241530880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a040faf346a49f9917f85a89f5c275c",
            "value": 241530880
          }
        },
        "5baf385be8734545b0147c7be560a93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dda626232ea4e3eb54d4373b97e57e3",
              "IPY_MODEL_3ca6c128612247ada560a885c64a3f4b"
            ],
            "layout": "IPY_MODEL_a68ef2d7615e4a2ea59b60096641feda"
          }
        },
        "6ca6783e279b4ed284614216481e9531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a040faf346a49f9917f85a89f5c275c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "a68ef2d7615e4a2ea59b60096641feda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb638aee7419466f8f4be88131bdafe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db01eaf8d2194977a50b4da6ce333ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
